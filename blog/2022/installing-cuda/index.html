<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Installing CUDA | MAI Minh's Page </title> <meta name="author" content="N. A. Minh MAI"> <meta name="description" content="Computer Science Blog | Nguyen Anh Minh MAI, AI Research Engineer "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/logo_minh.png?a7cf9880c438f18bb5f6425fa92f16c2"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://maiminh1996.github.io//blog/2022/installing-cuda/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> MAI Minh's Page </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/repositories/">repositories</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Installing CUDA</h1> <p class="post-meta"> Created in August 02, 2022 by MAI Minh </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fa-solid fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/tag/cuda"> <i class="fa-solid fa-hashtag fa-sm"></i> cuda</a>   <a href="/blog/tag/installing"> <i class="fa-solid fa-hashtag fa-sm"></i> installing</a>   ·   <a href="/blog/category/deep-learning"> <i class="fa-solid fa-tag fa-sm"></i> Deep-Learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <hr> <h3 id="introduction">Introduction</h3> <p>In this guide, we will lead you through the essential steps to set up a deep learning-based application, which involves installing NVIDIA GPUs, CUDA, and cuDNN. Additionally, we’ll explore how to upgrade your CUDA environment and even demonstrate how to manage multiple CUDA versions on a single machine for maximum flexibility and efficiency.</p> <h3 id="preinstall">Preinstall</h3> <p>Let’s perform some pre-installation checks about system, GPU device, its <a href="#compute-capability"><em>compute capability</em></a> to ensure that our system meets the necessary <a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions" rel="external nofollow noopener" target="_blank">requirements</a>:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="s2">"*** CUDA-capable GPU ***"</span>
lspci | <span class="nb">grep</span> <span class="nt">-i</span> nvidia
<span class="nb">echo</span> <span class="s2">"*** GPU compute capability ***"</span>
nvidia-smi <span class="nt">--query-gpu</span><span class="o">=</span>compute_cap <span class="nt">--format</span><span class="o">=</span>csv
<span class="nb">echo</span> <span class="s2">"*** CUDA cores number ***"</span>
nvidia-settings <span class="nt">-q</span> CUDACores <span class="nt">-t</span>
<span class="nb">echo</span> <span class="s2">"*** Linux version ***"</span>
<span class="nb">uname</span> <span class="nt">-m</span> <span class="o">&amp;&amp;</span> <span class="nb">cat</span> /etc/<span class="k">*</span>release
<span class="nb">echo</span> <span class="s2">"*** gcc version ***"</span>
gcc <span class="nt">--version</span> | <span class="nb">grep</span> <span class="s2">"gcc"</span> | <span class="nb">awk</span> <span class="s1">'{print $4}'</span>
<span class="nb">echo</span> <span class="s2">"*** Kernel version ***"</span>
<span class="nb">uname</span> <span class="nt">-r</span>
</code></pre></div></div> <p>Check if CUDA Toolkit and NVIDIA driver are already installed we may think of <a href="#upgrade">upgrade</a> instead:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="s2">"*** NVIDIA driver version ***"</span>
nvidia-smi | <span class="nb">grep</span> <span class="s2">"Driver Version"</span> | <span class="nb">awk</span> <span class="s1">'{print $6}'</span>
<span class="nb">echo</span> <span class="s2">"*** CUDA Toolkit version ***"</span>
nvcc <span class="nt">--version</span> | <span class="nb">grep</span> <span class="s2">"release"</span> | <span class="nb">awk</span> <span class="s1">'{print $6}'</span> | <span class="nb">cut</span> <span class="nt">-c2-</span>
<span class="nb">echo</span> <span class="s2">"*** cuDNN version ***"</span>
locate cudnn | <span class="nb">grep</span> <span class="s2">"libcudnn.so."</span> <span class="c"># | tail -n1 | sed -r 's/^.*\.so\.//'</span>
</code></pre></div></div> <h3 id="install">Install</h3> <p>In order to run a CUDA-based application, the system should have a CUDA enabled GPU and an NVIDIA display driver that is compatible with the CUDA Toolkit (<strong>CUDA-enabled GPU + NVIDIA driver + CUDA Toolkit + (cuDNN)</strong>) that was used to build the application itself.</p> <h4 id="nvidia-graphics-driver">NVIDIA graphics driver</h4> <p>Note: if you plan to install <a href="#cuda-toolkit">CUDA Toolkit</a> later, you can skip this step as CUDA Toolkit includes the necessary drivers.</p> <p><a href="https://www.nvidia.com/Download/index.aspx?lang=en-us" rel="external nofollow noopener" target="_blank">NVIDIA driver</a> includes the <a href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html" rel="external nofollow noopener" target="_blank"><em>CUDA (driver) library</em></a> designed for low-level CUDA programming. When linking a CUDA-based program, we typically use the shared library named <code class="language-plaintext highlighter-rouge">libcuda.so</code>, and its corresponding header file is called <code class="language-plaintext highlighter-rouge">cuda.h</code>.</p> <p>To install NVIDIA driver, we download the recommended driver <code class="language-plaintext highlighter-rouge">.run</code> file for our GPU from <a href="https://www.nvidia.com/Download/index.aspx?lang=en-us" rel="external nofollow noopener" target="_blank">NVIDIA Driver Downloads</a>. For example, if we have a GPU <code class="language-plaintext highlighter-rouge">GeForce RTX 2070 Mobile</code>, the recommended driver version is <code class="language-plaintext highlighter-rouge">535.86.05</code>.</p> <p><img src="../../../assets/img/nvidia_driver1.png" alt=""></p> <p><img src="../../../assets/img/nvidia_driver2.png" alt=""></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># e.g. fiel: NVIDIA-Linux-x86_64-535.86.05.run</span>
<span class="nb">chmod</span> +x &lt;file.run&gt;
<span class="nb">sudo</span> ./&lt;file.run&gt;
</code></pre></div></div> <p>Reboot your computer and verify that the NVIDIA graphics driver can be loaded:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvidia-smi
<span class="c"># +-----------------------------------------------------------------------------+</span>
<span class="c"># | NVIDIA-SMI 535.54.03   Driver Version: 535.54.03     CUDA Version: 12.2     |</span>
<span class="c"># |-------------------------------+----------------------+----------------------+</span>
<span class="c"># | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span>
<span class="c"># | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span>
<span class="c"># |                               |                      |               MIG M. |</span>
<span class="c"># |===============================+======================+======================|</span>
<span class="c"># |   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |</span>
<span class="c"># | N/A   55C    P8     7W /  N/A |    396MiB /  7982MiB |     13%      Default |</span>
<span class="c"># |                               |                      |                  N/A |</span>
<span class="c"># +-------------------------------+----------------------+----------------------+</span>
<span class="c">#</span>
<span class="c"># +-----------------------------------------------------------------------------+</span>
<span class="c"># | Processes:                                                                  |</span>
<span class="c"># |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span>
<span class="c"># |        ID   ID                                                   Usage      |</span>
<span class="c"># |=============================================================================|</span>
<span class="c"># |    0   N/A  N/A      5848      G   /usr/lib/xorg/Xorg                150MiB |</span>
<span class="c"># |    0   N/A  N/A      7386      G   /usr/bin/gnome-shell               75MiB |</span>
<span class="c"># |    0   N/A  N/A      8099      G   /usr/lib/firefox/firefox          168MiB |</span>
<span class="c"># +-----------------------------------------------------------------------------+</span>
</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>find /usr/ <span class="nt">-name</span> cuda.h
<span class="c"># /usr/src/linux-headers-5.15.0-78/include/uapi/linux/cuda.h</span>
<span class="c"># /usr/src/linux-headers-5.15.0-78/include/linux/cuda.h</span>
<span class="c"># /usr/src/linux-headers-5.15.0-76/include/uapi/linux/cuda.h</span>
<span class="c"># /usr/src/linux-headers-5.15.0-76/include/linux/cuda.h</span>
<span class="c"># /usr/src/linux-headers-5.4.0-122/include/uapi/linux/cuda.h</span>
<span class="c"># /usr/src/linux-headers-5.4.0-122/include/linux/cuda.h</span>
<span class="c"># /usr/include/linux/cuda.h</span>
<span class="c"># /usr/local/cuda-12.2/targets/x86_64-linux/include/cuda.h</span>
<span class="c"># /usr/local/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/cuda.h</span>
<span class="c"># /usr/local/lib/python3.9/site-packages/triton/third_party/cuda/include/cuda.h</span>
<span class="c"># /usr/local/lib/python3.9/site-packages/nvidia/cuda_runtime/include/cuda.h</span>
<span class="c"># /usr/local/cuda-11.0/targets/x86_64-linux/include/cuda.h</span>

<span class="nb">sudo </span>find /usr/ <span class="nt">-name</span> libcuda.<span class="k">*</span>
<span class="c"># /usr/lib/x86_64-linux-gnu/libcuda.so.1</span>
<span class="c"># /usr/lib/x86_64-linux-gnu/libcuda.so</span>
<span class="c"># /usr/lib/x86_64-linux-gnu/libcuda.so.535.54.03</span>
<span class="c"># /usr/lib/i386-linux-gnu/libcuda.so.1</span>
<span class="c"># /usr/lib/i386-linux-gnu/libcuda.so</span>
<span class="c"># /usr/lib/i386-linux-gnu/libcuda.so.535.54.03</span>
<span class="c"># /usr/local/cuda-12.2/targets/x86_64-linux/lib/stubs/libcuda.so</span>
<span class="c"># /usr/local/cuda-11.0/targets/x86_64-linux/lib/stubs/libcuda.so</span>
<span class="c"># /usr/local/cuda-11.0/doc/man/man7/libcuda.7</span>
<span class="c"># /usr/local/cuda-11.0/doc/man/man7/libcuda.so.7</span>
</code></pre></div></div> <p>It appears that the NVIDIA Driver version is <code class="language-plaintext highlighter-rouge">535.54.03</code>.</p> <h4 id="cuda-toolkit-cuda">CUDA Toolkit (CUDA)</h4> <p><a href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html" rel="external nofollow noopener" target="_blank"><em>CUDA Runtime library</em></a> is an essential component of the <a href="https://docs.nvidia.com/cuda/" rel="external nofollow noopener" target="_blank">CUDA Toolkit</a>, specifically designed for high-level CUDA programming. <strong>When installing the NVIDIA CUDA Toolkit, the NVIDIA driver will also be automatically installed</strong>. To link our CUDA-based program, we typically use the shared library named <code class="language-plaintext highlighter-rouge">libcudart.so</code>, and its corresponding header file is <code class="language-plaintext highlighter-rouge">cuda_runtime.h</code>.</p> <p>To install CUDA Toolkit, we choose the appropriate version of CUDA Toolkit to download and install from <a href="https://developer.nvidia.com/cuda-toolkit-archive" rel="external nofollow noopener" target="_blank">CUDA Toolkit Archive</a>. For example, we want to choose the latest CUDA Toolkit version which is <a href="https://developer.nvidia.com/cuda-downloads" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">CUDA Toolkit 12.2.0</code></a>.</p> <p><img src="../../../assets/img/cuda_toolkit1.png" alt=""></p> <p>Set up the repository and install CUDA Toolkit using the following cmds:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Package pinning mechanism: set a specific version of a package to prevent automatic upgrades by the package manager.</span>
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
<span class="nb">sudo mv </span>cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
<span class="c"># Download and add the necessary repository configuration of the CUDA Toolkit deb file for Ubuntu 22.04 (amd64 architecture) with version 12.2.0 to the APT package manager.</span>
wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda-repo-ubuntu2204-12-2-local_12.2.0-535.54.03-1_amd64.deb
<span class="nb">sudo cp</span> /var/cuda-repo-ubuntu2204-12-2-local/cuda-<span class="k">*</span><span class="nt">-keyring</span>.gpg /usr/share/keyrings/
<span class="nb">sudo </span>dpkg <span class="nt">-i</span> cuda-repo-ubuntu2204-12-2-local_12.2.0-535.54.03-1_amd64.deb
<span class="c"># Update the local package list, ensuring that the system recognizes the newly added CUDA repository and its packages.</span>
<span class="nb">sudo </span>apt-get update
<span class="c"># apt search cuda | grep cuda</span>
<span class="c"># sudo apt-get install -s cuda # simulate</span>
<span class="nb">sudo </span>apt-get <span class="nb">install </span>cuda <span class="c"># default, may be not the version we want</span>
<span class="c"># sudo apt-get install cuda-12-2</span>
</code></pre></div></div> <p>We see that <strong>installing CUDA Toolkit includes CUDA driver (<code class="language-plaintext highlighter-rouge">cuda-drivers</code>)</strong>, tools for app creation, libraries, header files, and resources. The newer driver is overinstalled on top of the older driver. We can find the CUDA Toolkit and corresponding NVIDIA driver versions <a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#id5" rel="external nofollow noopener" target="_blank">here (table 3)</a>.</p> <p>After installation, some useful environment variables are required for CUDA programming on Linux. Add the following lines to your <code class="language-plaintext highlighter-rouge">~/.bashrc</code> file:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="s1">'
# Set to the root directory of the CUDA installation
export CUDA_HOME="$CUDA_HOME:/usr/local/cuda"
export CUDA_PATH="$CUDA_PATH:/usr/local/cuda"
# Add the CUDA binary path to the existing $PATH
export PATH="$PATH:/usr/local/cuda/bin"
# Add the CUDA library path to the existing $LD_LIBRARY_PATH
export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:/usr/local/cuda/lib64"
# Set it to a comma-separated list of GPU device indices
# export CUDA_VISIBLE_DEVICES=0,1
# Set 1 to disable
# export CUDA_CACHE_DISABLE=1
'</span> <span class="o">&gt;&gt;</span> ~/.bashrc
<span class="nb">source</span> ~/.bashrc
</code></pre></div></div> <p>Some useful <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars" rel="external nofollow noopener" target="_blank">environment variables</a> used in CUDA programming on Linux:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">CUDA_HOME</code>, <code class="language-plaintext highlighter-rouge">CUDA_PATH</code>: helps various CUDA-related tools and compilers locate the necessary libraries and headers.</li> <li> <code class="language-plaintext highlighter-rouge">PATH</code>: easily access CUDA commands like <code class="language-plaintext highlighter-rouge">nvcc</code> (CUDA compiler), <code class="language-plaintext highlighter-rouge">cuda-gdb</code>, <code class="language-plaintext highlighter-rouge">cuda-memcheck</code>, <code class="language-plaintext highlighter-rouge">nvprof</code>, <code class="language-plaintext highlighter-rouge">nvprune</code>, etc.</li> <li> <code class="language-plaintext highlighter-rouge">LD_LIBRARY_PATH</code>: crucial for the dynamic linker to locate shared libraries required by CUDA applications at runtime.</li> <li> <code class="language-plaintext highlighter-rouge">CUDA_VISIBLE_DEVICES</code>: specify which GPU devices should be used by your CUDA program.</li> <li> <code class="language-plaintext highlighter-rouge">CUDA_CACHE_DISABLE</code>: disables the CUDA cache, which can be useful for debugging and profiling purposes.</li> </ul> <p>Reboot the computer and verify that the NVIDIA graphics driver can be loaded.</p> <p>Check if the CUDA Toolkit version has been installed successfully:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc <span class="nt">-V</span>
<span class="c"># nvcc: NVIDIA (R) Cuda compiler driver</span>
<span class="c"># Copyright (c) 2005-2023 NVIDIA Corporation</span>
<span class="c"># Built on Tue_Jun_13_19:16:58_PDT_2023</span>
<span class="c"># Cuda compilation tools, release 12.2, V12.2.91</span>
<span class="c"># Build cuda_12.2.r12.2/compiler.32965470_0</span>
</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>find /usr/ <span class="nt">-name</span> cuda_runtime.h
<span class="c"># /usr/local/cuda-12.2/targets/x86_64-linux/include/cuda_runtime.h</span>
<span class="c"># /usr/local/lib/python3.9/site-packages/nvidia/cuda_runtime/include/cuda_runtime.h</span>
<span class="c"># /usr/local/cuda-11.0/targets/x86_64-linux/include/cuda_runtime.h</span>

<span class="nb">sudo </span>find /usr/ <span class="nt">-name</span> libcudart.<span class="k">*</span>
<span class="c"># /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so.12</span>
<span class="c"># /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so.12.2.53</span>
<span class="c"># /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so</span>
<span class="c"># /usr/local/lib/python3.9/site-packages/nvidia/cuda_runtime/lib/libcudart.so.11.0</span>
<span class="c"># /usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0.221</span>
<span class="c"># /usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so</span>
<span class="c"># /usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0</span>
<span class="c"># /usr/local/cuda-11.0/doc/man/man7/libcudart.7</span>
<span class="c"># /usr/local/cuda-11.0/doc/man/man7/libcudart.so.7</span>
</code></pre></div></div> <p>It appears that the CUDA Toolkit version is <code class="language-plaintext highlighter-rouge">12.2</code>.</p> <h4 id="cudnn">cuDNN</h4> <p>CuDNN (CUDA Deep Neural Network Library), developed by NVIDIA, is a GPU-accelerated library specifically designed to enhance deep learning training and inference on NVIDIA GPUs.</p> <p>Based on <a href="https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#install-linux" rel="external nofollow noopener" target="_blank">Installing cuDNN on Linux</a>, we download the cuDNN <code class="language-plaintext highlighter-rouge">.tar</code> file corresponding to the CUDA Toolkit version from <a href="https://developer.nvidia.com/rdp/cudnn-archive" rel="external nofollow noopener" target="_blank">cuDNN Archive</a>.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cudnn-linux-x86_4-8.9.2.26_cuda12-archive.tar.xz</span>
<span class="nb">cd </span>Downloads/
<span class="nb">tar</span> <span class="nt">-zxvf</span> &lt;file.tar&gt;
<span class="nb">mv </span>cuda/ cudaX.Y
<span class="nb">sudo cp </span>cudaX.Y/include/<span class="k">*</span> /usr/local/cuda-X.Y/include/
<span class="nb">sudo cp </span>cudaX.Y/lib64/<span class="k">*</span> /usr/local/cuda-X.Y/lib64/
<span class="nb">sudo chmod </span>a+r /usr/local/cuda/lib64/libcudnn<span class="k">*</span>
</code></pre></div></div> <p>Check the installed cuDNN version if successful:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>locate cudnn | <span class="nb">grep</span> <span class="s2">"libcudnn.so."</span>
find /usr/ <span class="nt">-name</span> libcudnn<span class="k">*</span>
<span class="nb">cat</span> /usr/local/cuda/include/cudnn.h | <span class="nb">grep </span>CUDNN_MAJOR <span class="nt">-A</span> 2
<span class="nb">cat</span> /usr/local/cuda/include/cudnn_version.h | <span class="nb">grep </span>CUDNN_MAJOR <span class="nt">-A</span> 2 <span class="c"># for recent version</span>
</code></pre></div></div> <h3 id="upgrade">Upgrade</h3> <p>When upgrading the CUDA Toolkit, it is essential to <strong>ensure that the NVIDIA driver meets the minimum requirements of the targeted CUDA Toolkit version</strong>. We can find the necessary information about the compatible driver versions for each CUDA Toolkit in the <a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#id5" rel="external nofollow noopener" target="_blank">CUDA Toolkit and Corresponding Driver Versions (table 3)</a>.</p> <p>As explained in the <a href="https://docs.nvidia.com/deploy/cuda-compatibility/index.html" rel="external nofollow noopener" target="_blank">CUDA Compatibility</a>, <strong>CUDA upgrades are only backward compatible and not forward compatible</strong>. This means that applications or libraries compiled with an API from a newer CUDA/ NVIDIA driver version may not function correctly if you are using an environment with an older CUDA/ NVIDIA driver version. On the other hand, applications compiled with an API from an older version will work correctly if a newer version is installed.</p> <p>For example, consider the following example: A CUDA application compiled with CUDA <code class="language-plaintext highlighter-rouge">9.2</code> and a corresponding NVIDIA driver <code class="language-plaintext highlighter-rouge">396.37</code> may not work when executed on a system with CUDA <code class="language-plaintext highlighter-rouge">8.0</code> and NVIDIA driver version <code class="language-plaintext highlighter-rouge">367.48</code> due to the forward incompatibility. However, running an application compiled with CUDA <code class="language-plaintext highlighter-rouge">8.0</code> and NVIDIA driver <code class="language-plaintext highlighter-rouge">367.48</code> on a system with CUDA <code class="language-plaintext highlighter-rouge">9.2</code> and NVIDIA driver <code class="language-plaintext highlighter-rouge">396.37</code> will still function properly because of backward compatibility.</p> <p>To upgrade cuDNN, you can refer to the installation guide <a href="https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#upgrade" rel="external nofollow noopener" target="_blank">here</a>.</p> <h3 id="uninstall">Uninstall</h3> <p>Removing CUDA Toolkit, NVIDIA driver and other tools:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nt">--purge</span> remove <span class="s2">"*cuda*"</span> 
<span class="nb">sudo </span>apt-get <span class="nt">--purge</span> remove <span class="s2">"*nvidia*"</span>
<span class="nb">sudo </span>apt-get <span class="nt">--purge</span> remove <span class="s2">"*cublas*"</span> <span class="s2">"*cufft*"</span> <span class="s2">"*cufile*"</span> <span class="s2">"*curand*"</span> <span class="s2">"*cusolver*"</span> <span class="s2">"*cusparse*"</span> <span class="s2">"*gds-tools*"</span> <span class="s2">"*npp*"</span> <span class="s2">"*nvjpeg*"</span> <span class="s2">"nsight*"</span> 
<span class="nb">sudo </span>apt-get autoremove
<span class="nb">sudo rm</span> <span class="nt">-rf</span> /var/cuda-repo-X.Y.../
<span class="nb">sudo rm</span> <span class="nt">-rf</span> /usr/local/cuda-X.Y/ 
</code></pre></div></div> <h3 id="multi-cuda-version-on-one-machine">Multi CUDA version on one machine</h3> <p>Switch cuda by create a symbolic link into <code class="language-plaintext highlighter-rouge">/usr/local/cuda</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo ln</span> <span class="nt">-s</span> cuda-X.Y cuda
<span class="nb">ls</span> <span class="nt">-l</span> /usr/local <span class="c"># see cuda folder ref to cuda-X.Y</span>
</code></pre></div></div> <h3 id="conclusion">Conclusion</h3> <p>By the end of this guide, we will have a comprehensive understanding of NVIDIA GPUs, CUDA, and cuDNN, and you’ll be well-prepared to utilize GPU-accelerated computing for various applications. We provide references to official NVIDIA documentation for further exploration.</p> <h3 id="references">References</h3> <ol> <li>NVIDIA CUDA ToolKit X.Y Installation Guide for Linux: <a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html" rel="external nofollow noopener" target="_blank">docs.nvidia.com/cuda/archive/X.Y/cuda-installation-guide-linux/index.html</a> </li> <li>CUDA Toolkit and corresponding driver versions (table 3): <a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#id5" rel="external nofollow noopener" target="_blank">docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#id5</a> </li> <li>NVIDIA Driver Downloads: <a href="https://www.nvidia.com/Download/index.aspx?lang=en-us" rel="external nofollow noopener" target="_blank">nvidia.com/Download/index.aspx?lang=en-us</a> </li> <li>CUDA Toolkit Archive: <a href="https://developer.nvidia.com/cuda-toolkit-archive" rel="external nofollow noopener" target="_blank">developer.nvidia.com/cuda-toolkit-archive</a> </li> <li>cuDNN Archive: <a href="https://developer.nvidia.com/rdp/cudnn-archive" rel="external nofollow noopener" target="_blank">developer.nvidia.com/rdp/cudnn-archive</a> </li> <li>Installing cuDNN on Linux <a href="https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#install-linux" rel="external nofollow noopener" target="_blank">docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#install-linux</a> </li> <li>CUDA Compatibility: <a href="https://docs.nvidia.com/deploy/cuda-compatibility/index.html" rel="external nofollow noopener" target="_blank">docs.nvidia.com/deploy/cuda-compatibility/index.html</a> </li> </ol> <h3 id="glossary">Glossary</h3> <h4 id="compute-capability">Compute capability</h4> <p>The compute capability of a GPU (also known as its <em>SM version</em> (SM: *Streaming multiprocessors)) determines its general specifications and available features. Programs use this number at runtime to determine the available hardware features on the GPU.</p> <p>We can check NVIDIA GPU’s compute capability <a href="https://developer.nvidia.com/cuda-gpus#compute" rel="external nofollow noopener" target="_blank">here</a> or by running this cmd:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># older cuda toolkit may not suport this feature</span>
nvidia-smi <span class="nt">--query-gpu</span><span class="o">=</span>compute_cap <span class="nt">--format</span><span class="o">=</span>csv
</code></pre></div></div> <p>Compute capability of a GPU is represented by a version number <code class="language-plaintext highlighter-rouge">X.Y</code> (!= CUDA version) that indicates the supported features and instructions of the GPU hardware. GPUs sharing the same major revision number <code class="language-plaintext highlighter-rouge">X</code> in their compute capability have the same core architecture. For example, a GPU with a compute capability starting with <code class="language-plaintext highlighter-rouge">7.Y</code> is based on the Volta architecture, <code class="language-plaintext highlighter-rouge">8.Y</code> indicates the Ampere architecture, and so forth. Minor version numbers <code class="language-plaintext highlighter-rouge">Y</code> represent incremental improvements to the base architecture. For instance, Turing is assigned a compute capability of <code class="language-plaintext highlighter-rouge">7.5</code> as it is an incremental update to the Volta architecture. For deep learning-based purpose, you need to make sure that the compute capability of the GPU is at least <code class="language-plaintext highlighter-rouge">3.0</code> (Kepler architecture).</p> <p>Check out <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications-feature-support-per-compute-capability" rel="external nofollow noopener" target="_blank">Feature Support per Compute Capability (table 14)</a> and <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications-technical-specifications-per-compute-capability" rel="external nofollow noopener" target="_blank">Technical Specifications per Compute Capability (table 15)</a> to see if a specific GPU is support for a specific feacture or not.</p> <p>List NVIDIA GPUs architecture Compute Capability:</p> <ul> <li>Tesla (2006), CC: <code class="language-plaintext highlighter-rouge">1.Y</code> </li> <li>Fermi (2010), CC: <code class="language-plaintext highlighter-rouge">2.Y</code> </li> <li>Kepler (2012), CC: <code class="language-plaintext highlighter-rouge">3.Y</code> </li> <li>Maxwell (2014), CC: <code class="language-plaintext highlighter-rouge">5.Y</code> </li> <li>Pascal (2016), CC: <code class="language-plaintext highlighter-rouge">6.Y</code> </li> <li>Volta (2018), CC: <code class="language-plaintext highlighter-rouge">7.Y</code>. Turing (late 2018), based on the Volta architecture, CC: <code class="language-plaintext highlighter-rouge">7.5</code> </li> <li>Ampere (2020), CC: <code class="language-plaintext highlighter-rouge">8.Y</code> </li> <li>Hopper (2022), CC: <code class="language-plaintext highlighter-rouge">9.Y</code> </li> </ul> <h3 id="appendix">Appendix</h3> <h4 id="errors">Errors</h4> <p>When cuda is false CUDA unavailable when pytorch 1.3.0, installed with cudatoolkit 10.1 Ref: <a href="https://github.com/pytorch/pytorch/issues/28321" rel="external nofollow noopener" target="_blank">https://github.com/pytorch/pytorch/issues/28321</a></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span><span class="nv">torch</span><span class="o">==</span>1.3.1+cu100 <span class="nv">torchvision</span><span class="o">==</span>0.4.2+cu100 <span class="nt">-f</span> https://download.pytorch.org/whl/torch_stable.html
</code></pre></div></div> <p>If unable to locate nvidia-410 –&gt; system setting –&gt; soft and update –&gt; choose the best serveur –&gt; retry</p> <p>Failed call to cuInit: <code class="language-plaintext highlighter-rouge">CUDA_ERROR_UNKNOWN</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>nvidia-modprobe
reboot
</code></pre></div></div> <p>If get error: E: Failed to fetch file: <code class="language-plaintext highlighter-rouge">/var/cuda-repo-ubuntu1604-11-2-local/</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo rm</span> /etc/apt/sources.list.d/cuda-ubuntu1604-11-2-local.list
</code></pre></div></div> <p>If cuDNN existing errors: The driver relies on an automatically generated <code class="language-plaintext highlighter-rouge">xorg.conf</code> file at <code class="language-plaintext highlighter-rouge">/etc/X11/xorg.conf</code>. If a custom-built <code class="language-plaintext highlighter-rouge">xorg.conf</code> file is present, this functionality will be disabled and the driver may not work. You can try removing the existing <code class="language-plaintext highlighter-rouge">xorg.conf</code> file, or adding the contents of <code class="language-plaintext highlighter-rouge">/etc/X11/xorg.conf.d/00-nvidia.conf</code> to the xorg.conf file. The xorg.conf file will most likely need manual tweaking for systems with a non-trivial GPU configuration.</p> <h4 id="successful-configs">Successful configs</h4> <ul> <li>GeForce GTX 1080 Ti/PCIe/SSE2: python3.6, Pytorch 1.0.2, cuda 10.0, driver nvidia-410, cudnn 7.4.2</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/enabling-copy-paste-image-markdown/">Enabling image copy-paste in markdown</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/c-testing-with-gtest/">C++ Testing with GTest</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/tmux/">Tmux: An Introduction to Terminal Multiplexing</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/vim/">Basic Vim Usage</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/python-testing-with-pytest/">Python Testing with pytest</a> </li> <div id="disqus_thread" style="max-width: 930px; margin: 0 auto;"> <script type="text/javascript">var disqus_shortname="https-maiminh1996-github-io-5",disqus_identifier="/blog/2022/installing-cuda",disqus_title="Installing CUDA";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by Disqus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 N. A. Minh MAI. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-",title:"",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-repositories",title:"repositories",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-enabling-image-copy-paste-in-markdown",title:"Enabling image copy-paste in markdown",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/enabling-copy-paste-image-markdown/"}},{id:"post-c-testing-with-gtest",title:"C++ Testing with GTest",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/c-testing-with-gtest/"}},{id:"post-tmux-an-introduction-to-terminal-multiplexing",title:"Tmux: An Introduction to Terminal Multiplexing",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/tmux/"}},{id:"post-basic-vim-usage",title:"Basic Vim Usage",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/vim/"}},{id:"post-python-testing-with-pytest",title:"Python Testing with pytest",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/python-testing-with-pytest/"}},{id:"post-docker-inside-vs-code",title:"Docker inside VS Code",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/docker-inside-vs-code/"}},{id:"post-expert-advice-for-successful-research",title:"Expert Advice for Successful Research",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/research/"}},{id:"post-good-advice-and-tips",title:"Good advice and tips",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/good-advice-and-tips/"}},{id:"post-docker",title:"Docker",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/docker/"}},{id:"post-loss-function",title:"Loss function",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/loss-function/"}},{id:"post-glossary-ml",title:"Glossary ML",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/glossary/"}},{id:"post-disable-gradient-computation",title:"Disable gradient computation",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/disable-gradient-computation/"}},{id:"post-mastering-google-colab-tips-and-tricks",title:"Mastering Google Colab: Tips and Tricks",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/google-colab/"}},{id:"post-linear-algebra",title:"linear algebra",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/algebra/"}},{id:"post-python-data-structure",title:"Python data structure",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/python-data-structure/"}},{id:"post-math",title:"Math",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/math/"}},{id:"post-git-commit-message",title:"git Commit Message",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/git-commit-message/"}},{id:"post-git-best-pratice",title:"git best pratice",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/git-best-pratice/"}},{id:"post-setting-up-vs-code",title:"Setting up VS Code",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/vscode/"}},{id:"post-git-synthesis",title:"Git Synthesis",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/git/"}},{id:"post-installing-cuda",title:"Installing CUDA",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/installing-cuda/"}},{id:"post-installing-opencv",title:"Installing OpenCV",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/installing-opencv/"}},{id:"post-pihole-camera",title:"Pihole Camera",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/pihole-camera/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6D%61%69%6E%67%75%79%65%6E%61%6E%68%6D%69%6E%68%31%39%39%36@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=lxTC9IIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/maiminh1996","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/nguyen-anh-minh-mai","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>